{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messing around with reinforcement learning and multi-agent trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from itertools import product, combinations, permutations\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_table:\n",
    "\n",
    "    def __init__(self,\n",
    "                 Np = 31,\n",
    "                 Nv = 10, \n",
    "                 Nx = 15,\n",
    "                 initial_values = None):\n",
    "\n",
    "        self.Np = range(Np)\n",
    "        self.Nv = range(Nv)\n",
    "\n",
    "        states = list(product(self.Np, self.Nv))\n",
    "\n",
    "        self.Q = {s:np.zeros(Nx) for s in states}\n",
    "\n",
    "        # if initial_values is not None:\n",
    "        #     self.Q = initial_values\n",
    "        \n",
    "    def get_Q_value(self, state, action):\n",
    "        return self.Q[state][action]\n",
    "\n",
    "    def get_best_action(self, state):\n",
    "        return np.argmax(self.Q[state])\n",
    "\n",
    "    def get_best_value(self, state):\n",
    "        return np.max(self.Q[state])\n",
    "\n",
    "    def update(self, state, action, value):\n",
    "        self.Q[state][action] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed-point iteration methods for solving discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_chiN(I, xi, sigma_u, sigma_v, theta, tol=1e-12, max_iter=10000):\n",
    "    \"\"\"\n",
    "    Solve for the noncollusive slope chi^N in the Kyle-type model.\n",
    "\n",
    "    We use the 3-equation system from Section 3.2 in the paper:\n",
    "      (1) chi^N = 1 / [(I+1)*lambda^N]\n",
    "      (2) lambda^N = [theta * gamma^N + xi] / (theta + xi^2)\n",
    "      (3) gamma^N = (I*chi^N) / [(I*chi^N)^2 + (sigma_u/sigma_v)^2]\n",
    "\n",
    "    We do simple fixed-point iteration over chi^N.\n",
    "\n",
    "    Returns:\n",
    "      float: chi^N\n",
    "    \"\"\"\n",
    "    chi = 0.1  # Arbitrary initial guess\n",
    "    for _ in range(max_iter):\n",
    "        # Given chi, compute gamma^N:\n",
    "        gamma = (I * chi) / ((I * chi)**2 + (sigma_u / sigma_v)**2)\n",
    "\n",
    "        # Then lambda^N:\n",
    "        lam = (theta * gamma + xi) / (theta + xi**2)\n",
    "\n",
    "        # Then the updated chi^N:\n",
    "        new_chi = 1.0 / ((I + 1) * lam)\n",
    "\n",
    "        if abs(new_chi - chi) < tol:\n",
    "            return new_chi\n",
    "        chi = new_chi\n",
    "\n",
    "    raise RuntimeError(\"solve_chiN did not converge within max_iter\")\n",
    "\n",
    "\n",
    "def solve_chiM(I, xi, sigma_u, sigma_v, theta, tol=1e-12, max_iter=10000):\n",
    "    \"\"\"\n",
    "    Solve for the *perfect-collusion* slope chi^M in the Kyle-type model.\n",
    "\n",
    "    From Section 3.3 in the paper:\n",
    "      (1) chi^M = 1 / [2*I * lambda^M]\n",
    "      (2) lambda^M = [theta * gamma^M + xi] / (theta + xi^2)\n",
    "      (3) gamma^M = (I*chi^M) / [(I*chi^M)^2 + (sigma_u/sigma_v)^2]\n",
    "\n",
    "    Similar fixed-point iteration as above.\n",
    "    \"\"\"\n",
    "    chi = 0.1  # Arbitrary initial guess\n",
    "    for _ in range(max_iter):\n",
    "        gamma = (I * chi) / ((I * chi)**2 + (sigma_u / sigma_v)**2)\n",
    "        lam = (theta * gamma + xi) / (theta + xi**2)\n",
    "        new_chi = 1.0 / (2.0 * I * lam)\n",
    "\n",
    "        if abs(new_chi - chi) < tol:\n",
    "            return new_chi\n",
    "        chi = new_chi\n",
    "\n",
    "    raise RuntimeError(\"solve_chiM did not converge within max_iter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed (potentially) Collusive Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 3\n",
    "class InformedAgent:\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            Np = 31,\n",
    "            Nv = 10,\n",
    "            Nx = 15, \n",
    "            \n",
    "            rho = 0.95, \n",
    "            alpha = 0.01, \n",
    "            beta = 1e-5,\n",
    "            \n",
    "            sigma_v = 1,\n",
    "            v_bar = 1,\n",
    "            sigma_u = 0.1,\n",
    "            xi = 500,\n",
    "            theta = 0.1,\n",
    "            iota = 0.1\n",
    "            ):\n",
    "        \n",
    "        \n",
    "        # parameters\n",
    "        self.n_actions = Nx\n",
    "        self.Np = Np\n",
    "        self.Nv = Nv\n",
    "        self.n_states = Np * Nv\n",
    "\n",
    "        self.rho = rho\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        self.sigma_v = sigma_v\n",
    "        self.v_bar = v_bar\n",
    "\n",
    "        # Q-table for RL\n",
    "        self.Q = Q_table(Np = Np, Nv = Nv, Nx = Nx)\n",
    "\n",
    "        # state count dictionary for epsilon decay\n",
    "        self.state_count = defaultdict(int)\n",
    "\n",
    "        # discretization of states\n",
    "        # v\n",
    "        self.v_discrete = self.get_grid_point_values_v()\n",
    "        # x\n",
    "        chiN = solve_chiN(I = I, xi = xi, sigma_u = sigma_u, sigma_v = sigma_v, theta = theta)\n",
    "        chiM = solve_chiM(I = I, xi = xi, sigma_u = sigma_u, sigma_v = sigma_v, theta = theta)\n",
    "        x_n, x_m = chiN, chiM # assuming v - v_bar = 1\n",
    "        span = abs(x_n - x_m)\n",
    "        low, high = - max(x_n, x_m) - iota * span, max(x_n, x_m) + iota * span\n",
    "        self.x_discrete = np.linspace(low, high, Nx)\n",
    "        # p\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # self.p_disc\n",
    "    \n",
    "    def get_epsilon(self, state):\n",
    "        v = self.state_count[state]\n",
    "        self.state_count[state] += 1\n",
    "        return np.exp(-self.beta * v)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        epsilon = self.get_epsilon(state)\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.n_actions)\n",
    "        else:\n",
    "            return self.Q.get_best_action(state)\n",
    "        \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        learning = self.alpha * (reward + self.rho * self.Q.get_best_value(next_state))\n",
    "        memory = (1 - self.alpha) * self.Q.get_Q_value(state, action)\n",
    "        value = learning + memory\n",
    "        self.Q.update(state, action, value)\n",
    "    \n",
    "    def get_grid_point_values_v(self):\n",
    "        \"\"\"\n",
    "        Returns a zero indexed dictionary of the grid points for the state space of v\n",
    "        \"\"\"\n",
    "        standard_normal = torch.distributions.Normal(0, 1)\n",
    "        grid_point = [(2 * k - 1) / (2 * self.Nv) for k in range(1, self.Nv + 1)]\n",
    "        values = standard_normal.icdf(torch.tensor(grid_point))\n",
    "        return {idx: float(self.v_bar + self.sigma_v * value) for idx, value in enumerate(values)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: -0.6448533535003662, 1: -0.03643333911895752, 2: 0.32551026344299316, 3: 0.6146795153617859, 4: 0.8743386268615723, 5: 1.1256613731384277, 6: 1.3853204250335693, 7: 1.6744897365570068, 8: 2.036433696746826, 9: 2.644853353500366}\n"
     ]
    }
   ],
   "source": [
    "a = InformedAgent(Nv = 10)\n",
    "print(a.v_discrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preferred Habitat Investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreferredHabitatAgent:\n",
    "\n",
    "    def __init__(self, xi = 500, v_bar = 1):\n",
    "        self.xi = xi\n",
    "        self.v_bar = v_bar\n",
    "\n",
    "    def get_action(self, pt):\n",
    "        z = -self.xi * (pt - self.v_bar)\n",
    "        return z\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Market Makers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircularBuffer:\n",
    "    \"\"\"\n",
    "    Circular buffer for storing historical data.\n",
    "    \"\"\"\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.buffer = np.zeros(size)\n",
    "        self.index = 0\n",
    "\n",
    "    def add(self, value):\n",
    "        self.buffer[self.index] = value\n",
    "        self.index = (self.index + 1) % self.size\n",
    "\n",
    "    def get(self):\n",
    "        return np.concatenate((self.buffer[self.index:], self.buffer[:self.index]))\n",
    "\n",
    "class AdaptiveMarketMaker:\n",
    "\n",
    "    def __init__(self, theta, Tm):\n",
    "        self.theta = theta\n",
    "        self.Tm = Tm\n",
    "\n",
    "        self.vars_ = ['v','p','z','y']\n",
    "        self.historical_data = {var: CircularBuffer(size = self.Tm) for var in self.vars_}\n",
    "\n",
    "    def OLS(self, y, X):\n",
    "        \"\"\"\n",
    "        Perform Ordinary Least Squares (OLS) regression.\n",
    "        Parameters:\n",
    "        y (CircularBuffer): The dependent variable.\n",
    "        X (CircularBuffer): The independent variable(s).\n",
    "        Returns:\n",
    "        coef_ (ndarray): The estimated coefficients for the linear regression model.\n",
    "        \"\"\"\n",
    "        y = y.get()\n",
    "        X = X.get()\n",
    "        \n",
    "        X = np.vstack([X, np.ones(len(X))]).T\n",
    "        coef_, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "        return coef_\n",
    "    \n",
    "    def determine_price(self, yt):\n",
    "        \"\"\"\n",
    "        Determines the price based on historical data and a given input.\n",
    "        This method uses Ordinary Least Squares (OLS) regression to calculate\n",
    "        yt (float): The input value for which the price needs to be determined.\n",
    "        Returns:\n",
    "        float: The determined price based on the input `yt`.\n",
    "        \"\"\"\n",
    "\n",
    "        xi_1, xi_0 = self.OLS(self.historical_data['z'], self.historical_data['p'])\n",
    "        gamma_1, gamma_0 = self.OLS(self.historical_data['v'], self.historical_data['y'])\n",
    "        lambda_ = (xi_1 + self.theta * gamma_1) / (xi_1**2 + self.theta)\n",
    "        price = gamma_0 + lambda_ * yt\n",
    "        return price\n",
    "    \n",
    "    def update(self, vt, pt, zt, yt):\n",
    "        \"\"\"\n",
    "        Updates the historical data with the given values.\n",
    "        Parameters:\n",
    "        vt (float): The value of `v` at time `t`.\n",
    "        pt (float): The value of `p` at time `t`.\n",
    "        zt (float): The value of `z` at time `t`.\n",
    "        yt (float): The value of `y` at time `t`.\n",
    "        \"\"\"\n",
    "        for var, value in zip(self.vars_, [vt, pt, zt, yt]):\n",
    "            self.historical_data[var].add(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseAgent:\n",
    "    def __init__(self, sigma = 0.1):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def get_action(self):\n",
    "        return np.random.normal(scale = self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(T = 1000000):\n",
    "    market_maker = AdaptiveMarketMaker()\n",
    "    noise_agent = NoiseAgent()\n",
    "    preferred_habitat_agent = PreferredHabitatAgent()\n",
    "    informed_agents = [InformedAgent() for _ in range(I)]\n",
    "    _pt = 1\n",
    "    for t in range(T):\n",
    "\n",
    "        ut = noise_agent.get_action()\n",
    "        yt = []\n",
    "        # state = (_pt, )\n",
    "        for agent in informed_agents:\n",
    "            yt.append(agent.get_action())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
