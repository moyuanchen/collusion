{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from agents import *\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_next_v(v_bar = 1, sigma_v = 1):\n",
    "    return v_bar + np.random.normal(scale = sigma_v)\n",
    "\n",
    "def simulate(\n",
    "        T = 1000000, config = None,     # simulation time and config file\n",
    "        continue_simulation = False,    # continue simulation if True\n",
    "        save_path = None                # path to save the simulation\n",
    "        ):\n",
    "    assert config is not None, \"Config file required\"\n",
    "    I = config.I\n",
    "    Np = config.Np\n",
    "    Nv = config.Nv\n",
    "    Nx = config.Nx\n",
    "    sigma_u = config.sigma_u\n",
    "    if type(continue_simulation) == str:\n",
    "        log = np.load(continue_simulation, allow_pickle=True).item()\n",
    "        \n",
    "        v_hist = np.zeros(T)\n",
    "        p_hist = np.zeros(T)\n",
    "        z_hist = np.zeros(T)\n",
    "        x_hist = np.zeros((I, T))\n",
    "        # y_hist = np.zeros((I, T))\n",
    "        u_hist = np.zeros(T)\n",
    "        profit_hist = np.zeros((I, T))\n",
    "        t0 = 0\n",
    "\n",
    "        informed_agents = log[\"agents\"][\"informed\"]\n",
    "        noise_agent = log[\"agents\"][\"noise\"]\n",
    "        preferred_habitat_agent = log[\"agents\"][\"preferred_habitat\"]\n",
    "        market_maker = log[\"agents\"][\"market_maker\"]\n",
    "\n",
    "        _state = log[\"last_state\"]\n",
    "\n",
    "        convergence_counter = log['convergence_counter']\n",
    "    # elif type(continue_simulation) == dict:\n",
    "    #     log = continue_simulation\n",
    "    #     v_hist = log[\"v\"]\n",
    "    #     p_hist = log[\"p\"]\n",
    "    #     z_hist = log[\"z\"]\n",
    "    #     x_hist = log[\"x\"]\n",
    "    #     y_hist = log[\"y\"]\n",
    "    #     profit_hist = log[\"profit\"]\n",
    "    #     t0 = len(v_hist)\n",
    "    #     informed_agents = log[\"agents\"][\"informed\"]\n",
    "    #     noise_agent = log[\"agents\"][\"noise\"]\n",
    "    #     preferred_habitat_agent = log[\"agents\"][\"preferred_habitat\"]\n",
    "    #     market_maker = log[\"agents\"][\"market_maker\"]\n",
    "    #     _state = log[\"last_state\"]\n",
    "\n",
    "    #     profit_hist = np.concatenate((profit_hist, np.zeros((I, T))), axis=1)\n",
    "    #     v_hist = np.concatenate((v_hist, np.zeros(T)))\n",
    "    #     p_hist = np.concatenate((p_hist, np.zeros(T)))\n",
    "    #     z_hist = np.concatenate((z_hist, np.zeros(T)))\n",
    "    #     x_hist = np.concatenate((x_hist, np.zeros((I, T))), axis=1)\n",
    "    #     y_hist = np.concatenate((y_hist, np.zeros((I, T))), axis=1)\n",
    "\n",
    "    #     convergence_counter = log['convergence_counter']\n",
    "        \n",
    "    elif continue_simulation == False:\n",
    "\n",
    "        market_maker = AdaptiveMarketMaker(config)\n",
    "        noise_agent = NoiseAgent(config)\n",
    "        preferred_habitat_agent = PreferredHabitatAgent(config)\n",
    "        informed_agents = [InformedAgent(config) for _ in range(I)]\n",
    "        _state = (np.random.choice(Np), np.random.choice(Nv))\n",
    "\n",
    "        # log histories\n",
    "        v_hist = np.zeros(T)\n",
    "        p_hist = np.zeros(T)\n",
    "        z_hist = np.zeros(T)\n",
    "        x_hist = np.zeros((I, T))\n",
    "        # y_hist = np.zeros((I, T))\n",
    "        u_hist = np.zeros(T)\n",
    "        profit_hist = np.zeros((I, T))\n",
    "        t0 = 0\n",
    "        convergence_counter = 0\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for continue_simulation\")\n",
    "    for agent in informed_agents:\n",
    "        agent.convergence_counter = convergence_counter\n",
    "    if save_path is None:\n",
    "        save_path = '/Users/moyuanchen/Documents/thesis/data.npy'\n",
    "\n",
    "    for t in tqdm(range(T), desc=\"Simulation Progress\"):\n",
    "        yt = []\n",
    "        _p, _v = informed_agents[0].p_discrete[_state[0]], informed_agents[0].v_discrete[_state[1]]\n",
    "        v_hist[t+t0] = _v\n",
    "        p_hist[t+t0] = _p\n",
    "        _x = []\n",
    "        for idx, agent in enumerate(informed_agents):\n",
    "            x = agent.get_action(_state)\n",
    "            xd = agent.x_discrete[x]\n",
    "            yt.append(xd)\n",
    "            _x.append(x)\n",
    "\n",
    "            x_hist[idx, t + t0] = xd\n",
    "            # y_hist[idx, t + t0] = yt[-1]\n",
    "        ut = noise_agent.get_action()\n",
    "        u_hist[t+t0] = ut\n",
    "        yt_sum = np.sum(yt) + ut\n",
    "        # print(yt_sum)\n",
    "        zt = preferred_habitat_agent.get_action(_p)\n",
    "\n",
    "        z_hist[t+t0] = zt\n",
    "\n",
    "        market_maker.update(_v, _p, zt, yt_sum)\n",
    "        pt = market_maker.determine_price(yt_sum)\n",
    "        vt = get_next_v()\n",
    "        next_state = informed_agents[0].continuous_to_discrete(pt, vt)\n",
    "        for idx, agent in enumerate(informed_agents):\n",
    "            reward = (_v - pt) * yt[idx]\n",
    "            agent.update(_state, _x[idx], reward, next_state)\n",
    "            profit_hist[idx, t + t0] = reward\n",
    "\n",
    "        _state = next_state\n",
    "    convergence = min([agent.convergence_counter for agent in informed_agents])\n",
    "    log = {\n",
    "        \"v\": v_hist,\n",
    "        \"p\": p_hist,\n",
    "        \"z\": z_hist,\n",
    "        \"x\": x_hist,\n",
    "        \"u\": u_hist,\n",
    "        \"profit\": profit_hist,\n",
    "        \"last_state\": _state,\n",
    "        \"convergence_counter\": convergence\n",
    "    }\n",
    "    agents = {\n",
    "        \"informed\": informed_agents,\n",
    "        \"noise\": noise_agent,\n",
    "        \"preferred_habitat\": preferred_habitat_agent,\n",
    "        \"market_maker\": market_maker\n",
    "    }\n",
    "    log[\"agents\"] = agents\n",
    "    np.save(save_path, log)\n",
    "    # print(max_c)\n",
    "    return log, agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate $\\sigma_u = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation Progress:  74%|███████▎  | 367680/500000 [01:18<00:28, 4685.20it/s]"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.sigma_u = 0.1\n",
    "\n",
    "_save_path = '/Users/moyuanchen/Documents/thesis/sim_1/data_part_0.npy'\n",
    "log, agents = simulate(config = config, T = 500000, save_path=_save_path)\n",
    "convergence_threshold = 1000000\n",
    "convergence = 0\n",
    "partitions = 1\n",
    "while convergence < convergence_threshold:\n",
    "    save_path = f'/Users/moyuanchen/Documents/thesis/sim_1/data_part_{partitions}.npy'\n",
    "    log, agents = simulate(config = config, T=500000, continue_simulation=_save_path, save_path=save_path)\n",
    "    _save_path = save_path\n",
    "    \n",
    "    convergence = log['convergence_counter']\n",
    "    print(f\"Partition {partitions} completed, convergence counter: {convergence}\")\n",
    "    partitions += 1\n",
    "\n",
    "# save config\n",
    "np.save('/Users/moyuanchen/Documents/thesis/sim_1/config.npy', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.sigma_u = 100\n",
    "\n",
    "_save_path = '/Users/moyuanchen/Documents/thesis/sim_2/data_part_0.npy'\n",
    "log, agents = simulate(config = config, T = 500000, save_path=_save_path)\n",
    "convergence_threshold = 1000000\n",
    "convergence = 0\n",
    "partitions = 1\n",
    "while convergence < convergence_threshold:\n",
    "    save_path = f'/Users/moyuanchen/Documents/thesis/sim_1/data_part_{partitions}.npy'\n",
    "    log, agents = simulate(config = config, T=500000, continue_simulation=_save_path, save_path=save_path)\n",
    "    _save_path = save_path\n",
    "    \n",
    "    convergence = log['convergence_counter']\n",
    "    print(f\"Partition {partitions} completed, convergence counter: {convergence}\")\n",
    "    partitions += 1\n",
    "\n",
    "# save config\n",
    "np.save('/Users/moyuanchen/Documents/thesis/sim_1/config.npy', config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
